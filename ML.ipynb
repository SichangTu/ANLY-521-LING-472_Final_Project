{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui8AEFjuTIDT",
        "colab_type": "code",
        "outputId": "6bd17555-2c1d-43de-ee80-1cebf7a9dba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ6iXJK_WNPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plot\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "np.random.seed(93)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qHgAYijTUp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Adv_PY/Final_Project')\n",
        "from util import preprocess_text, shuffle_dataset, split_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ozY94XQoLD5",
        "colab_type": "code",
        "outputId": "c87419b3-929f-4ce2-a166-037138300197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKcbGCCZTVKR",
        "colab_type": "code",
        "outputId": "fa440f64-0fb4-4d93-afe8-24146179fc63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "filename = '/content/drive/My Drive/Adv_PY/Final_Project/data.txt'\n",
        "\n",
        "read_file = df = pd.read_table(filename, sep='\\t',header=None,names=['label','msg'])\n",
        "read_file.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>msg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                                msg\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWae1a_fTe-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train, test sets\n",
        "with open(filename, encoding='utf-8') as f:\n",
        "  texts = f.read().splitlines()\n",
        "\n",
        "labels = []\n",
        "corpus = []\n",
        "for text in texts:\n",
        "    label, msg = preprocess_text(text)\n",
        "    labels.append(label)\n",
        "    corpus.append(msg)\n",
        "\n",
        "train, test = split_data(corpus, labels, 0.2)\n",
        "y_train = np.asarray(train[1]).astype('int32').reshape((-1,1))\n",
        "y_test = np.asarray(test[1]).astype('int32').reshape((-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM44JTEDTfwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feture extraction using countvectorizer and tfidfvectorizer\n",
        "\n",
        "def count_vec(train, test):\n",
        "    count_vector = CountVectorizer()\n",
        "    train_vec = count_vector.fit_transform(train)\n",
        "    test_vec = count_vector.transform(test)\n",
        "    return train_vec, test_vec\n",
        "\n",
        "\n",
        "def tfidf_vec(train, test):\n",
        "    tfidf_vec = TfidfVectorizer()\n",
        "    train_vec = tfidf_vec.fit_transform(train)\n",
        "    test_vec = tfidf_vec.transform(test)\n",
        "    return train_vec, test_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-957DACMY9GJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define models\n",
        "\n",
        "def MN_NB():\n",
        "    clf = MultinomialNB()\n",
        "\n",
        "    return clf\n",
        "\n",
        "\n",
        "def RF():\n",
        "    parameters1 = {'n_estimators':[n for n in range(50, 300, 50)], \n",
        "                   'criterion':[\"gini\", \"entropy\"], \n",
        "                   'max_depth':(None, 4, 8, 12, 16, 20, 24, 50),\n",
        "                   'min_samples_split': (2, 4, 6, 8, 10, 20, 30),\n",
        "                   'min_samples_leaf': (16, 4, 12)}\n",
        "\n",
        "    clf = GridSearchCV(RandomForestClassifier(), \n",
        "                       parameters1, \n",
        "                       cv=5, \n",
        "                       n_jobs=-1, \n",
        "                       scoring=\"accuracy\")\n",
        "    \n",
        "    return clf\n",
        "\n",
        "\n",
        "def xgb(X_train, y_train, X_test):\n",
        "    num_of_runs = 10\n",
        "    if not os.path.exists('optimization_result.csv'):\n",
        "        os.mknod('optimization_result.csv')\n",
        "        \n",
        "    optimization_output_path = \"optimization_result.csv\"\n",
        "    \n",
        "    hyper_list = []\n",
        "    n = 1\n",
        "    for i in range(num_of_runs):\n",
        "        print(f\"Training model {n} out of {num_of_runs}\")\n",
        "        learning_rate = np.random.uniform(0.001, 0.15)\n",
        "        max_depth = np.random.choice([3, 4, 5, 6])\n",
        "        n_estimators = np.random.randint(low=50, high=180)\n",
        "        subsample = min(np.random.uniform(0.6, 1.1), 1.0)\n",
        "        colsample_bytree = min(np.random.uniform(0.6, 1.1), 1.0)\n",
        "\n",
        "        params = {'learning_rate': learning_rate,                                   \n",
        "                  'max_depth': max_depth,                                           \n",
        "                  'n_estimators': n_estimators,\n",
        "                  'subsample': subsample,                                           \n",
        "                  'colsample_bytree': colsample_bytree}                  \n",
        "        print(params)\n",
        "\n",
        "        clf = XGBClassifier(learning_rate=learning_rate,\n",
        "                                 objective='binary:logistic',\n",
        "                                 random_state=42,\n",
        "                                 n_jobs=8,\n",
        "                                 n_estimators=n_estimators,\n",
        "                                 max_depth=max_depth,\n",
        "                                 subsample=subsample,\n",
        "                                 colsample_bytree=colsample_bytree)\n",
        "        \n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        preds = clf.predict(X_test)\n",
        "        print(classification_report(y_test, preds))\n",
        "        acc = accuracy_score(y_test, preds)\n",
        "        params['acc'] = acc\n",
        "\n",
        "        hyper_list.append(pd.DataFrame(params, index=[0]))\n",
        "        n = n + 1\n",
        "\n",
        "    hyper_df = pd.concat(hyper_list)\n",
        "    hyper_df.sort_values('acc', inplace=True, ascending=False)\n",
        "    hyper_df.reset_index(drop=True, inplace=True)\n",
        "    hyper_df.to_csv(optimization_output_path)\n",
        "\n",
        "    best_clf = XGBClassifier(learning_rate=hyper_df['learning_rate'][0],\n",
        "                             objective='binary:logistic', \n",
        "                             random_state=42,\n",
        "                             n_jobs=8, \n",
        "                             n_estimators=hyper_df['n_estimators'][0], \n",
        "                             max_depth=hyper_df['max_depth'][0], \n",
        "                             subsample=hyper_df['subsample'][0],\n",
        "                             colsample_bytree=hyper_df['colsample_bytree'][0])\n",
        "    \n",
        "    return best_clf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5FzHPXZc5pS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit and evaluate model\n",
        "def fit_eval(model, X_train, y_train, X_test, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    print(classification_report(y_test, preds))\n",
        "    print(f\"accuracy score: {accuracy_score(y_test, preds)}\")\n",
        "    print(\"\\n=========================\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndEe46WYc5_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_count, test_count = count_vec(train[0], test[0])\n",
        "train_tf, test_tf = tfidf_vec(train[0], test[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn9XMtObGdNw",
        "colab_type": "text"
      },
      "source": [
        "### Train and evaluate models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDrvr4STc6bo",
        "colab_type": "code",
        "outputId": "86efb705-aa73-4093-d14d-4efb56ed0285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "source": [
        "naive_bayes = MN_NB()\n",
        "print(\"CountVectorizer:\")\n",
        "fit_eval(naive_bayes, train_count, y_train, test_count, y_test)\n",
        "print(\"TfidfVectorizer:\")\n",
        "fit_eval(naive_bayes, train_tf, y_train, test_tf, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CountVectorizer:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       984\n",
            "           1       0.96      0.96      0.96       130\n",
            "\n",
            "    accuracy                           0.99      1114\n",
            "   macro avg       0.98      0.98      0.98      1114\n",
            "weighted avg       0.99      0.99      0.99      1114\n",
            "\n",
            "accuracy score: 0.9910233393177738\n",
            "=========================\n",
            "TfidfVectorizer:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       984\n",
            "           1       1.00      0.74      0.85       130\n",
            "\n",
            "    accuracy                           0.97      1114\n",
            "   macro avg       0.98      0.87      0.92      1114\n",
            "weighted avg       0.97      0.97      0.97      1114\n",
            "\n",
            "accuracy score: 0.9694793536804309\n",
            "=========================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzIdehMbqNts",
        "colab_type": "code",
        "outputId": "937d7498-7b8a-45fc-f9db-9053afe26acc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "source": [
        "random_forest = RF()\n",
        "print(\"CountVectorizer:\")\n",
        "fit_eval(random_forest, train_count, y_train, test_count, y_test)\n",
        "print(\"TfidfVectorizer:\")\n",
        "fit_eval(random_forest, train_tf, y_train, test_tf, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CountVectorizer:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.best_estimator_.fit(X, y, **fit_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       984\n",
            "           1       1.00      0.82      0.90       130\n",
            "\n",
            "    accuracy                           0.98      1114\n",
            "   macro avg       0.99      0.91      0.94      1114\n",
            "weighted avg       0.98      0.98      0.98      1114\n",
            "\n",
            "accuracy score: 0.9784560143626571\n",
            "=========================\n",
            "TfidfVectorizer:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.best_estimator_.fit(X, y, **fit_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       984\n",
            "           1       1.00      0.82      0.90       130\n",
            "\n",
            "    accuracy                           0.98      1114\n",
            "   macro avg       0.99      0.91      0.95      1114\n",
            "weighted avg       0.98      0.98      0.98      1114\n",
            "\n",
            "accuracy score: 0.9793536804308797\n",
            "=========================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9S8RJkQ0f5C",
        "colab_type": "code",
        "outputId": "ee65562b-fdd1-4600-eed6-025e7fd7fe44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "xgb = xgb(train_count, y_train, test_count)\n",
        "print(\"CountVectorizer:\")\n",
        "fit_eval(xgb, train_count, y_train, test_count, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model 1 out of 10\n",
            "{'learning_rate': 0.03415269705840413, 'max_depth': 3, 'n_estimators': 85, 'subsample': 0.6961938113769657, 'colsample_bytree': 0.8260392830802796}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97       984\n",
            "           1       0.96      0.58      0.72       130\n",
            "\n",
            "    accuracy                           0.95      1114\n",
            "   macro avg       0.95      0.79      0.85      1114\n",
            "weighted avg       0.95      0.95      0.94      1114\n",
            "\n",
            "Training model 2 out of 10\n",
            "{'learning_rate': 0.0841867313434725, 'max_depth': 4, 'n_estimators': 60, 'subsample': 0.8140993803492083, 'colsample_bytree': 0.9015587924211335}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       984\n",
            "           1       0.96      0.69      0.80       130\n",
            "\n",
            "    accuracy                           0.96      1114\n",
            "   macro avg       0.96      0.84      0.89      1114\n",
            "weighted avg       0.96      0.96      0.96      1114\n",
            "\n",
            "Training model 3 out of 10\n",
            "{'learning_rate': 0.1012357493531761, 'max_depth': 3, 'n_estimators': 175, 'subsample': 0.770782216545549, 'colsample_bytree': 1.0}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       984\n",
            "           1       0.98      0.82      0.90       130\n",
            "\n",
            "    accuracy                           0.98      1114\n",
            "   macro avg       0.98      0.91      0.94      1114\n",
            "weighted avg       0.98      0.98      0.98      1114\n",
            "\n",
            "Training model 4 out of 10\n",
            "{'learning_rate': 0.007219406808590379, 'max_depth': 4, 'n_estimators': 73, 'subsample': 0.660667753855081, 'colsample_bytree': 0.7330597523240394}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.97       984\n",
            "           1       0.94      0.55      0.70       130\n",
            "\n",
            "    accuracy                           0.94      1114\n",
            "   macro avg       0.94      0.77      0.83      1114\n",
            "weighted avg       0.94      0.94      0.94      1114\n",
            "\n",
            "Training model 5 out of 10\n",
            "{'learning_rate': 0.09004802820783614, 'max_depth': 6, 'n_estimators': 80, 'subsample': 0.828804323968392, 'colsample_bytree': 0.7019212227583169}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99       984\n",
            "           1       0.99      0.80      0.89       130\n",
            "\n",
            "    accuracy                           0.98      1114\n",
            "   macro avg       0.98      0.90      0.94      1114\n",
            "weighted avg       0.98      0.98      0.97      1114\n",
            "\n",
            "Training model 6 out of 10\n",
            "{'learning_rate': 0.04758809447578645, 'max_depth': 3, 'n_estimators': 154, 'subsample': 1.0, 'colsample_bytree': 1.0}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       984\n",
            "           1       0.97      0.68      0.80       130\n",
            "\n",
            "    accuracy                           0.96      1114\n",
            "   macro avg       0.96      0.84      0.89      1114\n",
            "weighted avg       0.96      0.96      0.96      1114\n",
            "\n",
            "Training model 7 out of 10\n",
            "{'learning_rate': 0.013311401923610858, 'max_depth': 4, 'n_estimators': 173, 'subsample': 0.9122508603166303, 'colsample_bytree': 0.6702577291832297}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97       984\n",
            "           1       0.95      0.62      0.75       130\n",
            "\n",
            "    accuracy                           0.95      1114\n",
            "   macro avg       0.95      0.81      0.86      1114\n",
            "weighted avg       0.95      0.95      0.95      1114\n",
            "\n",
            "Training model 8 out of 10\n",
            "{'learning_rate': 0.1328017256273381, 'max_depth': 4, 'n_estimators': 70, 'subsample': 0.6892405138811349, 'colsample_bytree': 0.6584301968762583}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99       984\n",
            "           1       0.99      0.79      0.88       130\n",
            "\n",
            "    accuracy                           0.97      1114\n",
            "   macro avg       0.98      0.90      0.93      1114\n",
            "weighted avg       0.98      0.97      0.97      1114\n",
            "\n",
            "Training model 9 out of 10\n",
            "{'learning_rate': 0.13597977669646122, 'max_depth': 4, 'n_estimators': 114, 'subsample': 0.6134645757826748, 'colsample_bytree': 0.847822412839045}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       984\n",
            "           1       0.98      0.84      0.90       130\n",
            "\n",
            "    accuracy                           0.98      1114\n",
            "   macro avg       0.98      0.92      0.95      1114\n",
            "weighted avg       0.98      0.98      0.98      1114\n",
            "\n",
            "Training model 10 out of 10\n",
            "{'learning_rate': 0.030424389094931146, 'max_depth': 6, 'n_estimators': 66, 'subsample': 1.0, 'colsample_bytree': 0.9786462309250109}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98       984\n",
            "           1       0.95      0.68      0.79       130\n",
            "\n",
            "    accuracy                           0.96      1114\n",
            "   macro avg       0.95      0.84      0.88      1114\n",
            "weighted avg       0.96      0.96      0.95      1114\n",
            "\n",
            "CountVectorizer:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       984\n",
            "           1       0.98      0.84      0.90       130\n",
            "\n",
            "    accuracy                           0.98      1114\n",
            "   macro avg       0.98      0.92      0.95      1114\n",
            "weighted avg       0.98      0.98      0.98      1114\n",
            "\n",
            "accuracy score: 0.9793536804308797\n",
            "\n",
            "=========================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-lVxaqpMvMr",
        "colab_type": "code",
        "outputId": "bac8fe6c-a622-413b-e5b0-bcf072a63154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "xgb = xgb(train_tf, y_train, test_tf)\n",
        "print(\"CountVectorizer:\")\n",
        "fit_eval(xgb, train_tf, y_train, test_tf, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model 1 out of 10\n",
            "{'learning_rate': 0.05881570231084641, 'max_depth': 4, 'n_estimators': 174, 'subsample': 1.0, 'colsample_bytree': 0.8419389924711405}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       984\n",
            "           1       0.98      0.78      0.87       130\n",
            "\n",
            "    accuracy                           0.97      1114\n",
            "   macro avg       0.98      0.89      0.93      1114\n",
            "weighted avg       0.97      0.97      0.97      1114\n",
            "\n",
            "Training model 2 out of 10\n",
            "{'learning_rate': 0.028490552790031938, 'max_depth': 6, 'n_estimators': 167, 'subsample': 0.7656194119285389, 'colsample_bytree': 1.0}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       984\n",
            "           1       0.95      0.78      0.86       130\n",
            "\n",
            "    accuracy                           0.97      1114\n",
            "   macro avg       0.96      0.89      0.92      1114\n",
            "weighted avg       0.97      0.97      0.97      1114\n",
            "\n",
            "Training model 3 out of 10\n",
            "{'learning_rate': 0.0315608273925203, 'max_depth': 6, 'n_estimators': 179, 'subsample': 0.6429352779375384, 'colsample_bytree': 1.0}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       984\n",
            "           1       0.95      0.78      0.86       130\n",
            "\n",
            "    accuracy                           0.97      1114\n",
            "   macro avg       0.96      0.89      0.92      1114\n",
            "weighted avg       0.97      0.97      0.97      1114\n",
            "\n",
            "Training model 4 out of 10\n",
            "{'learning_rate': 0.012988331098229357, 'max_depth': 3, 'n_estimators': 164, 'subsample': 0.7842924128097727, 'colsample_bytree': 0.9427426930423433}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97       984\n",
            "           1       0.92      0.62      0.74       130\n",
            "\n",
            "    accuracy                           0.95      1114\n",
            "   macro avg       0.94      0.81      0.86      1114\n",
            "weighted avg       0.95      0.95      0.95      1114\n",
            "\n",
            "Training model 5 out of 10\n",
            "{'learning_rate': 0.12648905700520938, 'max_depth': 3, 'n_estimators': 81, 'subsample': 0.6618714833351712, 'colsample_bytree': 0.7048845396744949}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       984\n",
            "           1       0.97      0.77      0.86       130\n",
            "\n",
            "    accuracy                           0.97      1114\n",
            "   macro avg       0.97      0.88      0.92      1114\n",
            "weighted avg       0.97      0.97      0.97      1114\n",
            "\n",
            "Training model 6 out of 10\n",
            "{'learning_rate': 0.0014711119563535014, 'max_depth': 6, 'n_estimators': 92, 'subsample': 0.9805866819150135, 'colsample_bytree': 0.6715191264081449}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97       984\n",
            "           1       0.91      0.66      0.77       130\n",
            "\n",
            "    accuracy                           0.95      1114\n",
            "   macro avg       0.94      0.83      0.87      1114\n",
            "weighted avg       0.95      0.95      0.95      1114\n",
            "\n",
            "Training model 7 out of 10\n",
            "{'learning_rate': 0.08817704968024488, 'max_depth': 5, 'n_estimators': 122, 'subsample': 1.0, 'colsample_bytree': 0.6547877832641581}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       984\n",
            "           1       0.99      0.82      0.89       130\n",
            "\n",
            "    accuracy                           0.98      1114\n",
            "   macro avg       0.98      0.91      0.94      1114\n",
            "weighted avg       0.98      0.98      0.98      1114\n",
            "\n",
            "Training model 8 out of 10\n",
            "{'learning_rate': 0.14150321845673547, 'max_depth': 6, 'n_estimators': 90, 'subsample': 1.0, 'colsample_bytree': 0.632931001172816}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       984\n",
            "           1       0.99      0.82      0.89       130\n",
            "\n",
            "    accuracy                           0.98      1114\n",
            "   macro avg       0.98      0.91      0.94      1114\n",
            "weighted avg       0.98      0.98      0.98      1114\n",
            "\n",
            "Training model 9 out of 10\n",
            "{'learning_rate': 0.058028204023651705, 'max_depth': 5, 'n_estimators': 173, 'subsample': 0.9125909292114597, 'colsample_bytree': 0.88543997030023}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       984\n",
            "           1       0.98      0.82      0.89       130\n",
            "\n",
            "    accuracy                           0.98      1114\n",
            "   macro avg       0.98      0.91      0.94      1114\n",
            "weighted avg       0.98      0.98      0.98      1114\n",
            "\n",
            "Training model 10 out of 10\n",
            "{'learning_rate': 0.037372718076360514, 'max_depth': 5, 'n_estimators': 173, 'subsample': 0.6148726583887578, 'colsample_bytree': 0.7106701079584999}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       984\n",
            "           1       0.95      0.77      0.85       130\n",
            "\n",
            "    accuracy                           0.97      1114\n",
            "   macro avg       0.96      0.88      0.92      1114\n",
            "weighted avg       0.97      0.97      0.97      1114\n",
            "\n",
            "CountVectorizer:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       984\n",
            "           1       0.99      0.82      0.89       130\n",
            "\n",
            "    accuracy                           0.98      1114\n",
            "   macro avg       0.98      0.91      0.94      1114\n",
            "weighted avg       0.98      0.98      0.98      1114\n",
            "\n",
            "accuracy score: 0.9775583482944344\n",
            "\n",
            "=========================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}